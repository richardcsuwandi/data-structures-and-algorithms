{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artificial Neural Network on Bank Customers Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMb8+Nx+3YE5BltIeh+oZ3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richardcsuwandi/data-structures-and-algorithms/blob/master/Artificial%20Neural%20Network%20on%20Bank%20Customers%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjeIpGi8oV-d",
        "colab_type": "text"
      },
      "source": [
        "# Artificial Neural Network on Bank Customers Dataset\n",
        "\n",
        "This project is one of my Deep Learning projects. For this project, we have a [bank customers](https://github.com/richardcsuwandi/datasets/blob/master/bank_customers.csv) dataset that consists of a randomly sampled population of a banking customers detailing demographics and whether a customer left (or stayed at) the bank within the last 6 months.\n",
        "\n",
        "The goal of this project is create an Artificial Neural Network (ANN) model to classifiy whether a customer will stay or leave from the bank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoe8pvBjm_eC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e235f9cc-6e09-45f8-d45c-3e29d19b17d6"
      },
      "source": [
        "# Import the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ47MPoBqILK",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data\n",
        "First, we need to load the data from the `bank_customers.csv` file and convert it into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CM8zOronwdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "2cc7c192-ffd5-4f98-c06a-b725a585b072"
      },
      "source": [
        "# Import the data\n",
        "path = 'https://raw.githubusercontent.com/richardcsuwandi/datasets/master/bank_customers.csv'\n",
        "data_raw = pd.read_csv(path)\n",
        "\n",
        "# View the first 5 observations of the data\n",
        "data_raw.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOdh6Me0n6rN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "beeb1978-8a37-41be-b700-ca70a0018b0b"
      },
      "source": [
        "# View a more detailed summary of the data\n",
        "data_raw.describe(include='all')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2932</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Smith</td>\n",
              "      <td>NaN</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5014</td>\n",
              "      <td>5457</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>650.528800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.921800</td>\n",
              "      <td>5.012800</td>\n",
              "      <td>76485.889288</td>\n",
              "      <td>1.530200</td>\n",
              "      <td>0.70550</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>100090.239881</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2886.89568</td>\n",
              "      <td>7.193619e+04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>0.45584</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>0.402769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.556570e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2500.75000</td>\n",
              "      <td>1.562853e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51002.110000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>652.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97198.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100193.915000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7500.25000</td>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>718.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127644.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149388.247500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.581569e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          RowNumber    CustomerId  ... EstimatedSalary        Exited\n",
              "count   10000.00000  1.000000e+04  ...    10000.000000  10000.000000\n",
              "unique          NaN           NaN  ...             NaN           NaN\n",
              "top             NaN           NaN  ...             NaN           NaN\n",
              "freq            NaN           NaN  ...             NaN           NaN\n",
              "mean     5000.50000  1.569094e+07  ...   100090.239881      0.203700\n",
              "std      2886.89568  7.193619e+04  ...    57510.492818      0.402769\n",
              "min         1.00000  1.556570e+07  ...       11.580000      0.000000\n",
              "25%      2500.75000  1.562853e+07  ...    51002.110000      0.000000\n",
              "50%      5000.50000  1.569074e+07  ...   100193.915000      0.000000\n",
              "75%      7500.25000  1.575323e+07  ...   149388.247500      0.000000\n",
              "max     10000.00000  1.581569e+07  ...   199992.480000      1.000000\n",
              "\n",
              "[11 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWQqU6IkqsVi",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Data\n",
        "As we can see above, we don't have any missing values in our data. However, there are some columns that might not be useful for building our model e.g `RowNumber`, `CustomerId`, and `Surname`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwJNkZJRoTj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "acd839cb-c5e2-4936-b112-5e597a87c5b0"
      },
      "source": [
        "# Drop the 'RowNumber', 'CustomerId', and 'Surname' columns\n",
        "data = data_raw.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "0          619    France  Female  ...               1        101348.88       1\n",
              "1          608     Spain  Female  ...               1        112542.58       0\n",
              "2          502    France  Female  ...               0        113931.57       1\n",
              "3          699    France  Female  ...               0         93826.63       0\n",
              "4          850     Spain  Female  ...               1         79084.10       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34XOnCUcsLx7",
        "colab_type": "text"
      },
      "source": [
        "Next, we can declare the features and label in our dataset. Here, our label (column to predict) is the `Exited` column which contains either 0 (left) or 1 (stayed). All the other columns will be our features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQvZN4rhsBww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare the features and labels\n",
        "X = data.drop('Exited', axis=1)  # Features\n",
        "y = data['Exited']  # Label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_RwoiAGsycf",
        "colab_type": "text"
      },
      "source": [
        "Now, let's take a look at our features (X) and determine whether we need to further preprocess it or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic43ijMYsxvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d4375dab-167e-4fe6-a5dd-39381380755f"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0          619    France  Female  ...          1               1        101348.88\n",
              "1          608     Spain  Female  ...          0               1        112542.58\n",
              "2          502    France  Female  ...          1               0        113931.57\n",
              "3          699    France  Female  ...          0               0         93826.63\n",
              "4          850     Spain  Female  ...          1               1         79084.10\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G6MTFB-s__R",
        "colab_type": "text"
      },
      "source": [
        "We notice that we have two columns that contain categorical values: `Geography` and `Gender`. So, we are going to create dummy variables to need to convert those categorical values into numerical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UilFPQets_Vw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "829dfa8c-41e7-4fe5-912c-e794f9c6bf95"
      },
      "source": [
        "# Create dummy variables\n",
        "geo = pd.get_dummies(X['Geography'], drop_first=True)\n",
        "gender = pd.get_dummies(X['Gender'], drop_first=True)\n",
        "\n",
        "# Concatenate the dummy columns\n",
        "X = pd.concat([X, geo, gender], axis=1)\n",
        "\n",
        "# Drop the columns that are no longer required\n",
        "X = X.drop(['Geography', 'Gender'], axis=1)\n",
        "X.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  ...  EstimatedSalary  Germany  Spain  Male\n",
              "0          619   42       2       0.00  ...        101348.88        0      0     0\n",
              "1          608   41       1   83807.86  ...        112542.58        0      1     0\n",
              "2          502   42       8  159660.80  ...        113931.57        0      0     0\n",
              "3          699   39       1       0.00  ...         93826.63        0      0     0\n",
              "4          850   43       2  125510.82  ...         79084.10        0      1     0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpFhg-yUulZH",
        "colab_type": "text"
      },
      "source": [
        "Now, we can split our data into training and test sets. Following the Pareto principle, we are going to split the data with a ratio of 80:20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-b0NhDzvVtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Krtc45Lvs4_",
        "colab_type": "text"
      },
      "source": [
        "One last step is we need to do feature scaling on our data before building our model. To avoid any data leakage, we will fit the scaler on our training set only, then standardise the test set with that scaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcjsUT8bvl8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale our data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PFhM5l_weqG",
        "colab_type": "text"
      },
      "source": [
        "## Building our Model\n",
        "After cleaning and preprocessing our data, we are now ready to build our ANN model. Our data will consist of 2 dense (fully-connected) layers with ReLu activation functions and another 1 dense layer as our output layer with Sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SZ_Mpxyw-9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=11, units=6, activation='relu'))\n",
        "model.add(Dense(units=6, activation='relu', name='hid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTNm9B40xkEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "1b5baa6c-0f00-48e7-bce0-1f778eba8eda"
      },
      "source": [
        "# Get the architecture of our model\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "hid (Dense)                  (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYhK3eWby1KI",
        "colab_type": "text"
      },
      "source": [
        "Before training the model, we need to compile the model with the following settings:\n",
        "\n",
        "- Loss function: This measures how accurate the model is during training. For the loss function, we are going to use the binary cross entropy.\n",
        "- Optimizer: This is how the model is updated based on the data it sees and its loss function. We are going to use Adam, which is an optimization algorithm based on adaptive estimation of first-order and second-order moments.\n",
        "- Metrics: Used to monitor the training and testing steps. Here we will use accuracy, the fraction of the images that are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWKd6B6xgq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E805Cn5WzJ38",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can fit the training set to our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFHC6cgqzOji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba9557ee-40b3-4321-d218-99b4c4e79e76"
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, batch_size=10, epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 1s 126us/step - loss: 0.5324 - accuracy: 0.7843\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4420 - accuracy: 0.8105\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4269 - accuracy: 0.8167\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4220 - accuracy: 0.8198\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.4184 - accuracy: 0.8224\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4152 - accuracy: 0.8270\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4125 - accuracy: 0.8261\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4113 - accuracy: 0.8304\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 0.4095 - accuracy: 0.8299\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4078 - accuracy: 0.8326\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4060 - accuracy: 0.8313\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.4039 - accuracy: 0.8335\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4014 - accuracy: 0.8351\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 0.3979 - accuracy: 0.8347\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.3938 - accuracy: 0.8338\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3890 - accuracy: 0.8345\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3843 - accuracy: 0.8342\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3798 - accuracy: 0.8338\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3757 - accuracy: 0.8341\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3727 - accuracy: 0.8367\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3695 - accuracy: 0.8455\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.3670 - accuracy: 0.8475\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3650 - accuracy: 0.8495\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3632 - accuracy: 0.8522\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.3615 - accuracy: 0.8528\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3609 - accuracy: 0.8508\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3591 - accuracy: 0.8530\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3574 - accuracy: 0.8543\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3544 - accuracy: 0.8551\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3525 - accuracy: 0.8571\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3489 - accuracy: 0.8562\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3458 - accuracy: 0.8579\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3438 - accuracy: 0.8570\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3421 - accuracy: 0.8600\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3418 - accuracy: 0.8608\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3403 - accuracy: 0.8612\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 1s 104us/step - loss: 0.3398 - accuracy: 0.8599\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3392 - accuracy: 0.8602\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3383 - accuracy: 0.8620\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3384 - accuracy: 0.8605\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.3376 - accuracy: 0.8597\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.3374 - accuracy: 0.8614\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3379 - accuracy: 0.8602\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.3364 - accuracy: 0.8604\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3370 - accuracy: 0.8601\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3357 - accuracy: 0.8614\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3365 - accuracy: 0.8601\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3361 - accuracy: 0.8610\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.3361 - accuracy: 0.8610\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3361 - accuracy: 0.8599\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3356 - accuracy: 0.8594\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3354 - accuracy: 0.8601\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.3357 - accuracy: 0.8594\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3350 - accuracy: 0.8594\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3347 - accuracy: 0.8616\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3350 - accuracy: 0.8602\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 1s 104us/step - loss: 0.3341 - accuracy: 0.8608\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.3336 - accuracy: 0.8614\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 1s 114us/step - loss: 0.3340 - accuracy: 0.8601\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3332 - accuracy: 0.8621\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3339 - accuracy: 0.8616\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.3332 - accuracy: 0.8600\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3325 - accuracy: 0.8643\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3335 - accuracy: 0.8614\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.3330 - accuracy: 0.8622\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3330 - accuracy: 0.8605\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3327 - accuracy: 0.8614\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3328 - accuracy: 0.8622\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 1s 114us/step - loss: 0.3326 - accuracy: 0.8629\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.3326 - accuracy: 0.8594\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3329 - accuracy: 0.8609\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3327 - accuracy: 0.8614\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3330 - accuracy: 0.8610\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 1s 114us/step - loss: 0.3326 - accuracy: 0.8612\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3327 - accuracy: 0.8610\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3320 - accuracy: 0.8636\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3318 - accuracy: 0.8615\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3330 - accuracy: 0.8610\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3319 - accuracy: 0.8615\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3321 - accuracy: 0.8630\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3320 - accuracy: 0.8629\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.3318 - accuracy: 0.8601\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.3318 - accuracy: 0.8611\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3324 - accuracy: 0.8619\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.3319 - accuracy: 0.8610\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3324 - accuracy: 0.8616\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 1s 103us/step - loss: 0.3311 - accuracy: 0.8637\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3309 - accuracy: 0.8630\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.3317 - accuracy: 0.8630\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.3321 - accuracy: 0.8619\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.3317 - accuracy: 0.8635\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.3318 - accuracy: 0.8615\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.3310 - accuracy: 0.8631\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 0.3316 - accuracy: 0.8629\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.3312 - accuracy: 0.8633\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.3310 - accuracy: 0.8639\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.3318 - accuracy: 0.8625\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.3315 - accuracy: 0.8630\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.3318 - accuracy: 0.8610\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 1s 106us/step - loss: 0.3308 - accuracy: 0.8614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuK8CPCqzNjP",
        "colab_type": "text"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.86 (or 86%) on the training set. We can also visualize the plot for the loss for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Csow4f1z-dW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "21961a6c-fe74-415a-c9de-3d167bb9ebab"
      },
      "source": [
        "# Visualize the loss for each epoch\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqI-YY_6z--T",
        "colab_type": "text"
      },
      "source": [
        "With the model trained, we can now use it to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZzThOm_0G5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert into Boolean values\n",
        "y_pred = y_pred > 0.5"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmICOAX21ECF",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Model\n",
        "Lastly, let's evaluate our model on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm0qt0eg1AGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d2954d7c-f8e8-4c13-ac81-4524a3b31e55"
      },
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'The loss on the test set is: {test_loss}')\n",
        "print(f'The accuracy on the test set is: {test_acc}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 25us/step\n",
            "The loss on the test set is: 0.3315143666267395\n",
            "The accuracy on the test set is: 0.8640000224113464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXhGYZfM1gpE",
        "colab_type": "text"
      },
      "source": [
        "It turns out that the accuracy on the test dataset is a slightly higher than the accuracy on the training data. As another evaluation metric, we can create a confusion matrix to further examine our model's performace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y68yZf91ho8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4de15558-b278-4c35-e03f-aa17ed1720aa"
      },
      "source": [
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPvBd2Sj4xk4",
        "colab_type": "text"
      },
      "source": [
        "We can observe that our model is pretty good at classifying 0 values (customers leaving the bank) but not that good in the case where the values are 1 (customers that are actually staying). This is probably due to the imbalance amount of label in our data where our data contains a lot more 0 values than the 1 values."
      ]
    }
  ]
}